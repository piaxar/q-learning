{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "#np.random.seed(1335)  # for reproducibility\n",
    "np.set_printoptions(precision=5, suppress=True, linewidth=150)\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics, preprocessing\n",
    "from talib.abstract import *\n",
    "from sklearn.externals import joblib\n",
    "from keras import regularizers\n",
    "\n",
    "import quandl\n",
    "\n",
    "'''\n",
    "Name:        The Self Learning Quant, Example 3\n",
    "\n",
    "Author:      Daniel Zakrisson\n",
    "\n",
    "Created:     30/03/2016\n",
    "Copyright:   (c) Daniel Zakrisson 2016\n",
    "Licence:     BSD\n",
    "\n",
    "Requirements:\n",
    "Numpy\n",
    "Pandas\n",
    "MatplotLib\n",
    "scikit-learn\n",
    "TA-Lib, instructions at https://mrjbq7.github.io/ta-lib/install.html\n",
    "Keras, https://keras.io/\n",
    "quandl, https://www.quandl.com/tools/python\n",
    "backtest.py from the TWP library. Download backtest.py and put in the same folder\n",
    "\n",
    "/plt create a subfolder in the same directory where plot files will be saved\n",
    "\n",
    "'''\n",
    "\n",
    "#Load data\n",
    "\n",
    "def backtest(price, signal ,initialCash,to_sell=0.2):\n",
    "    shares=[]\n",
    "    cash=[]\n",
    "    dif=np.diff(signal)\n",
    "    dif=np.append([0],dif)\n",
    "    for i,sig in enumerate(dif):\n",
    "        if sig==100:\n",
    "            shares.append(100/price[i])\n",
    "            cash.append(-100)\n",
    "        elif sig==-100:\n",
    "            total_shares=sum(shares)*to_sell\n",
    "            total_value=total_shares*price[i]\n",
    "            cash.append(total_value)\n",
    "            shares.append(-total_shares)\n",
    "        else:\n",
    "            cash.append(0)\n",
    "            shares.append(0)\n",
    "    data = pd.DataFrame(columns = ['price','total_shares','shares_trade','value','cash','pnl'])\n",
    "    data['cash']=initialCash+np.cumsum(cash)\n",
    "    data['price']=price\n",
    "    data['signal']=signal\n",
    "    data['shares_trade']=shares\n",
    "    data['total_shares']=np.cumsum(shares)\n",
    "    data['value']=data['total_shares']*price\n",
    "    data['pnl']=data['cash']+data['value']-initialCash  \n",
    "    \n",
    "    return data\n",
    "    \n",
    "    \n",
    "\n",
    "def load_data_(file='bitcoin_hourly_recent.csv',size=24*60):\n",
    "    prices = pd.read_csv(file)\n",
    "    prices.rename(columns={'Open': 'open', 'High': 'high', \n",
    "     'Low': 'low', 'Close': 'close', 'Volume (BTC)': 'volume'}, inplace=True)\n",
    "    \n",
    "    index=np.random.randint(0,int(prices.shape[0] - size))    \n",
    "    prices_dummy=prices[index:index+size]\n",
    "        \n",
    "    return prices_dummy\n",
    "    \n",
    "    \n",
    "def split_train_test(data,train=0.8):\n",
    "    index2=int(data.shape[0]*0.8)\n",
    "    prices_train = data[0:index2]\n",
    "    prices_test = data[index2:]\n",
    "    \n",
    "    return prices_train, prices_test\n",
    "        \n",
    "  \n",
    "def make_attributes(indata, test=False,indicators=[]):\n",
    "    \n",
    "    close = indata['close'].values\n",
    "    diff = np.diff(close)\n",
    "    diff = np.insert(diff, 0, 0)\n",
    "    \n",
    "    res={'close':close,'diff':diff}\n",
    "    for key in indicators.keys():\n",
    "        indic=indicators[key]\n",
    "        print(key)\n",
    "        if len(indic)==2:\n",
    "            result = indic[0](indata,indic[1])\n",
    "        if len(indic)==1:\n",
    "            result = indic[0](indata)\n",
    "        try:\n",
    "            length=len(result.columns)\n",
    "        except:\n",
    "            length=1\n",
    "            \n",
    "        if length==1:   \n",
    "            res[key]=result\n",
    "        else:\n",
    "            for col in result.columns:\n",
    "                res[key+'_'+col]=result[col]\n",
    "        \n",
    "            \n",
    "    variables=pd.DataFrame(res)\n",
    "    \n",
    "    return variables\n",
    "    \n",
    "#Initialize first state, all items are placed deterministically\n",
    "def init_state(indata, test=False):    \n",
    "    #--- Preprocess data    \n",
    "    xdata = np.nan_to_num(indata.copy())\n",
    "    xdata = np.column_stack((xdata,np.zeros(len(xdata))))\n",
    "    if test == False:\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        xdata = np.expand_dims(scaler.fit_transform(xdata), axis=1)\n",
    "        joblib.dump(scaler, 'data/scaler.pkl')\n",
    "    elif test == True:\n",
    "        scaler = joblib.load('data/scaler.pkl')\n",
    "        xdata = np.expand_dims(scaler.fit_transform(xdata), axis=1)\n",
    "    state = xdata[0:1, 0:1, :]\n",
    "    \n",
    "    return xdata, indata['close']\n",
    "\n",
    "def make_state_steps(xdata,time_step,steps,cash,cash_norm):\n",
    "    state = xdata[time_step-steps:time_step]\n",
    "    state = state.reshape((1,steps,state.shape[2]))    \n",
    "    state[0,0:steps,-1] = cash/cash_norm\n",
    "    \n",
    "    return state\n",
    "    \n",
    "#Take Action\n",
    "def take_action(xdata, action, signal, time_step, steps, cash, cash_norm):\n",
    "    #this should generate a list of trade signals that at evaluation time are fed to the backtester\n",
    "    #the backtester should get a list of trade signals and a list of price data for the assett\n",
    "    \n",
    "    #make necessary adjustments to state and then return it\n",
    "    time_step += 1\n",
    "    new_state = make_state_steps(xdata,time_step,steps,cash,cash_norm)\n",
    "    \n",
    "    #move the market data window one step forward\n",
    "    previous = signal.loc[time_step - 1]\n",
    "    if np.isnan(previous):\n",
    "        previous=0.0\n",
    "        \n",
    "        \n",
    "    #if the current iteration is the last state (\"terminal state\") then set terminal_state to 1\n",
    "    if time_step + 1 == xdata.shape[0]:\n",
    "        terminal_state = 1\n",
    "    else:\n",
    "        terminal_state = 0  \n",
    "        \n",
    "    #take action\n",
    "    if action == 1:\n",
    "        #buy\n",
    "        if cash>100:\n",
    "            signal.iloc[time_step] = previous + 100\n",
    "        else:\n",
    "            signal.iloc[time_step] = signal.iloc[time_step - 1]\n",
    "    elif action == 2:\n",
    "        #do nothing\n",
    "        signal.iloc[time_step] = signal.iloc[time_step - 1]\n",
    "    elif action==0:\n",
    "        #sell\n",
    "        if previous>=100:\n",
    "            signal.loc[time_step] = previous - 100\n",
    "        elif previous<100 and previous>0:\n",
    "            signal.loc[time_step] = 0\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return new_state, time_step, signal, terminal_state\n",
    "\n",
    "#Get Reward, the reward is returned at the end of an episode\n",
    "def get_reward(time_step, action, price_data, signal, initial_cash, terminal_state, eval=False, epoch=0):\n",
    "    reward = 0\n",
    "    signal.fillna(value=0, inplace=True)\n",
    "\n",
    "    index1=None\n",
    "    index2=None\n",
    "    \n",
    "    if eval == False:\n",
    "        index1=time_step-2\n",
    "        index1=0\n",
    "        index2=time_step+1\n",
    "        \n",
    "    #bt = twp.Backtest(pd.Series(data=[x for x in price_data[index1:index2].values],index=signal[index1:index2].index.values), \n",
    "    #                            signal[index1:index2], initialCash=initial_cash)\n",
    "    \n",
    "    bt = backtest(price_data[index1:index2].values, signal[index1:index2].values, initialCash=initial_cash)\n",
    "    #reward = bt.data.pnl.values[-1]\n",
    "    \n",
    "    reward = bt.pnl.values[-1] - bt.pnl.values[-2]\n",
    "    cash = bt.cash.values[-1]\n",
    "    if cash<0.0:\n",
    "        asdasdf2=234234\n",
    "        \n",
    "    \n",
    "#    dif = bt.data.price.diff(1)     \n",
    "#    if dif.values[-1]>0 and action!=2:\n",
    "#        reward=reward-10\n",
    "#    if dif.values[-1]<0 and action==1:\n",
    "#        reward=reward+100+price\n",
    "#        \n",
    "#    if action==0 and cash==initial_cash:\n",
    "#        reward-=200\n",
    "    if action==2:\n",
    "        reward-=1\n",
    "    \n",
    "    return reward, cash, bt\n",
    "\n",
    "def plotTradesBuySell(data):\n",
    "    \"\"\" \n",
    "    visualise trades on the price chart \n",
    "    long entry : green triangle up\n",
    "    short entry : red triangle down\n",
    "    exit : black circle\n",
    "    \"\"\"\n",
    "    l = ['price']\n",
    "    \n",
    "    p = data['price']\n",
    "    p.plot(style='x-')\n",
    "    \n",
    "    d = data['signal'].diff()\n",
    "    d[0] = 0\n",
    "    idx = d > 0\n",
    "    if idx.any():\n",
    "        p[idx].plot(style='go')\n",
    "        l.append('buy')\n",
    "    \n",
    "    #colored line for short positions    \n",
    "    idx = d < 0\n",
    "    if idx.any():\n",
    "        p[idx].plot(style='ro',alpha=0.5)\n",
    "        l.append('sell')\n",
    "\n",
    "    plt.xlim([p.index[0],p.index[-1]]) # show full axis\n",
    "    \n",
    "    plt.legend(l,loc='best')\n",
    "    plt.title('trades')    \n",
    "    \n",
    "def plotTrades(bt,epoch):\n",
    "    #save a figure of the test set\n",
    "    plt.figure(figsize=(6,8))\n",
    "    plotTradesBuySell(bt)\n",
    "\n",
    "    plt.suptitle(str(epoch))\n",
    "    plt.savefig('plt/'+str(epoch)+'.png', bbox_inches='tight', pad_inches=1, dpi=72)\n",
    "    plt.close('all')\n",
    "    \n",
    "    \n",
    "    \n",
    "def run_Q(xdata, model, price_data, time_step, steps, signal, cash, cash_norm, epsilon):\n",
    "    \n",
    "    state = make_state_steps(xdata,time_step,steps,cash,cash_norm)\n",
    "\n",
    "    if (random.random() < epsilon): #choose random action\n",
    "        action = np.random.randint(0,3) #assumes 4 different actions\n",
    "    else: #choose best action from Q(s,a) values\n",
    "        qval = model.predict(state, batch_size=1)\n",
    "        action = (np.argmax(qval))\n",
    "    #Take action, observe new state S'\n",
    "    \n",
    "    new_state, time_step, signal, terminal_state = take_action(xdata=xdata, action=action, \n",
    "                                                               signal=signal, time_step=time_step, steps=steps,\n",
    "                                                               cash=cash, cash_norm=cash_norm)\n",
    "    #Observe reward\n",
    "    reward, cash, bt = get_reward(time_step=time_step, action=action, \n",
    "                        price_data = price_data, signal=signal, \n",
    "                        terminal_state=terminal_state,initial_cash=initial_cash)\n",
    "    new_state[0][0][-1] = cash/cash_norm\n",
    "    \n",
    "    return state, action, reward, new_state, cash, time_step, signal, terminal_state, bt\n",
    " \n",
    "    \n",
    "    \n",
    "def evaluate_Q(eval_data, eval_model, price_data, cash, steps, epoch=0,epsilon=0):\n",
    "    #This function is used to evaluate the performance of the system each epoch, without the influence of epsilon and random actions\n",
    "    signal = pd.Series(index=np.arange(len(eval_data)))\n",
    "    terminal_state = 0\n",
    "    #initiliaze time_step to steps, so that the index won't go below the first element\n",
    "    time_step = steps\n",
    "    rewards=[]\n",
    "    while(terminal_state != 1):\n",
    "        state, action, reward, new_state, cash, time_step, signal, terminal_state, bt = run_Q(xdata=xdata, \n",
    "                                                                                              model=model, \n",
    "                                         price_data=price_data,time_step=time_step, \n",
    "                                         signal=signal,cash=cash, cash_norm=cash_norm,epsilon=epsilon, steps=steps)\n",
    "        \n",
    "        rewards.append(reward)\n",
    "             \n",
    "    plotTrades(bt,epoch)\n",
    "            \n",
    "    return bt.pnl.values[-1], rewards, signal, bt\n",
    "\n",
    "#This neural network is the the Q-function, run it like this:\n",
    "#model.predict(state.reshape(1,64), batch_size=1)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "\n",
    "def create_model(data, steps):\n",
    "    model = Sequential()\n",
    "    #the +1 in the input_shape is for the available money\n",
    "    model.add(LSTM(data.shape[1],\n",
    "                   input_shape=(steps, data.shape[1]+1),\n",
    "                   return_sequences=False,\n",
    "                   stateful=False,activation='relu',kernel_regularizer=regularizers.l1(0.01)))\n",
    "#    model.add(Dropout(0.5))\n",
    "#    \n",
    "#    model.add(Dropout(0.5))\n",
    "    #model.add(Dense(30,input_shape=(data.shape[1]+1,)))\n",
    "    model.add(Dense(data.shape[1]*3))\n",
    "    model.add(Dropout(0.5))    \n",
    "    model.add(Dense(3, init='lecun_uniform'))\n",
    "    model.add(Activation('linear')) #linear output so we can have range of real-valued outputs\n",
    "    \n",
    "    model.compile(loss='mse', optimizer='nadam')\n",
    "    return model\n",
    "\n",
    "\n",
    "import random, timeit\n",
    "\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "#old\n",
    "#{'sma15':(SMA,15),'sma60':(SMA,60)'rsi14':(RSI,14),'atr14':(ATR,14)}\n",
    "\n",
    "data = load_data_()\n",
    "data = make_attributes(data,indicators={'sma12':(SMA,6),'sma12':(SMA,12),'sma24':(SMA,24),'sma48':(SMA,48),\n",
    "                                               'rsi6':(RSI,6),'rsi12':(RSI,12),'rsi24':(RSI,24),'rsi24':(RSI,48),\n",
    "                                               'atr6':(ATR,6),'atr12':(ATR,12),'atr24':(ATR,24),'atr48':(ATR,48),\n",
    "                                               'stoch6':(STOCH,6),'stoch12':(STOCH,12),'stoch24':(STOCH,24),'stoch48':(STOCH,48),\n",
    "                                               'bop6':(BOP,6),'bop12':(BOP,12),'bop24':(BOP,24),'bop48':(BOP,48),\n",
    "                                               'kama6':(KAMA,6),'kama12':(KAMA,12),'kama24':(KAMA,24),'kama48':(KAMA,48),\n",
    "                                               #'MAVP':(MAVP,24),\n",
    "                                               'MACD':(MACD,),\n",
    "                                               'HT_TRENDLINE':(HT_TRENDLINE ,),\n",
    "                                               'HT_DCPERIOD':(HT_DCPERIOD,),\n",
    "                                               'HT_SINE':(HT_SINE ,),\n",
    "                                               'HT_TRENDMODE':(HT_TRENDMODE,),\n",
    "                                               'CDL2CROWS':(CDL2CROWS,),\n",
    "                                               'CDLHAMMER':(CDLHAMMER ,),\n",
    "                                               'CDLHANGINGMAN':(CDLHANGINGMAN,),\n",
    "                                               'CDLENGULFING':(CDLENGULFING,),\n",
    "                                               'CDL3BLACKCROWS':(CDL3BLACKCROWS,),\n",
    "                                               'CDLDRAGONFLYDOJI':(CDLDRAGONFLYDOJI,),\n",
    "                                               'CDLENGULFING':(CDLENGULFING,),\n",
    "                                               'CDLMORNINGDOJISTAR':(CDLMORNINGDOJISTAR,),\n",
    "                                               'CDLRISEFALL3METHODS':(CDLRISEFALL3METHODS,),\n",
    "                                               'CDLUNIQUE3RIVER':(CDLUNIQUE3RIVER,)})\n",
    "\n",
    "#data['close-sma15'] = data['close'] - data['sma15']\n",
    "#data['sma15-sma60'] = data['sma15'] - data['sma60']\n",
    "#data.dropna(inplace=True)\n",
    "\n",
    "indata,test_data = split_train_test(data)\n",
    "xdata, price_data = init_state(indata)\n",
    "xdata_test, price_data_test = init_state(indata,test=True)\n",
    "\n",
    "\n",
    "\n",
    "#main parameters\n",
    "initial_cash=1000\n",
    "epochs = 50\n",
    "alpha=0.1\n",
    "gamma = 0.3 #higher values benefit longer term rewards\n",
    "epsilon = 0.5\n",
    "batchSize = 20\n",
    "buffer = 50\n",
    "steps = 12\n",
    "replay = []\n",
    "learning_progress = []\n",
    "\n",
    "#stores tuples of (S, A, R, S')\n",
    "\n",
    "h = 0\n",
    "#trading signal. All 0s in the beginning\n",
    "signal = pd.Series(index=np.arange(len(indata)))\n",
    "signal.fillna(value=0,inplace=True)\n",
    "\n",
    "#just a quick and dirty way to normalise the amount of cash available.\n",
    "cash_norm = initial_cash*2\n",
    "cash = initial_cash\n",
    "\n",
    "model=create_model(indata,steps)\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    terminal_state = 0\n",
    "    time_step = steps+1\n",
    "    #while game still in progress\n",
    "    while(terminal_state != 1):\n",
    "        #We are in state S\n",
    "        #Let's run our Q function on S to get Q values for all possible actions\n",
    "        \n",
    "        state, action, reward, new_state, cash, time_step, signal, terminal_state, _ = run_Q(xdata=xdata, model=model, \n",
    "                                                 price_data=price_data,time_step=time_step, \n",
    "                                                 signal=signal,cash=cash, cash_norm=cash_norm,epsilon=epsilon, steps=steps)\n",
    "\n",
    "        #Experience replay storage\n",
    "        if (len(replay) < buffer): #if buffer not filled, add to it\n",
    "            replay.append((state, action, reward, new_state))\n",
    "            #print(time_step, reward, terminal_state)\n",
    "        else: #if buffer full, overwrite old values\n",
    "            if (h < (buffer-1)):\n",
    "                h += 1\n",
    "            else:\n",
    "                h = 0\n",
    "            replay[h] = (state, action, reward, new_state)\n",
    "            #randomly sample our experience replay memory\n",
    "            minibatch = random.sample(replay, batchSize)\n",
    "            X_train = []\n",
    "            y_train = []\n",
    "            for memory in minibatch:\n",
    "                #Get max_Q(S',a)\n",
    "                old_state, action, reward, new_state = memory\n",
    "                old_qval = model.predict(old_state, batch_size=1)\n",
    "                newQ = model.predict(new_state, batch_size=1)\n",
    "                maxQ = np.max(newQ)\n",
    "                y = np.zeros((1,len(old_qval[0])))\n",
    "                y[:] = old_qval[:]\n",
    "                if terminal_state == 0: #non-terminal state\n",
    "                    update = (reward + (gamma * maxQ))\n",
    "                else: #terminal state\n",
    "                    update = reward\n",
    "                y[0][action] = (1-alpha)*y[0][action] + alpha*update\n",
    "                #print(time_step, reward, terminal_state)\n",
    "                X_train.append(old_state)\n",
    "                y_train.append(y.reshape(len(old_qval[0]),))\n",
    "\n",
    "            X_train = np.squeeze(np.array(X_train), axis=(1))\n",
    "            y_train = np.array(y_train)\n",
    "            model.fit(X_train, y_train, batch_size=batchSize, epochs=1, verbose=1)           \n",
    "            state = new_state\n",
    "\n",
    "    eval_reward, rewards, signal, bt = evaluate_Q(eval_data = xdata_test, eval_model = model, price_data = price_data_test, \n",
    "                             epoch=i, cash=initial_cash, steps=steps)\n",
    "    bt.to_csv('epoch_data/epoch_'+str(i)+'.csv')\n",
    "    \n",
    "    learning_progress.append((eval_reward))\n",
    "    print(\"Epoch #: %s Reward: %f Epsilon: %f\" % (i,eval_reward, epsilon))\n",
    "    #learning_progress.append((reward))\n",
    "    if epsilon > 0.1: #decrement epsilon over time\n",
    "        epsilon -= (1.0/epochs)\n",
    "\n",
    "\n",
    "elapsed = np.round(timeit.default_timer() - start_time, decimals=2)\n",
    "print(\"Completed in %f\" % (elapsed,))\n",
    "\n",
    "#bt = twp.Backtest(pd.Series(data=[x[0,0] for x in xdata]), signal, signalType='shares')\n",
    "#bt.data['delta'] = bt.data['shares'].diff().fillna(0)\n",
    "#\n",
    "#print(bt.data)\n",
    "#unique, counts = np.unique(filter(lambda v: v==v, signal.values), return_counts=True)\n",
    "#print(np.asarray((unique, counts)).T)\n",
    "#\n",
    "#plt.figure()\n",
    "#plt.subplot(3,1,1)\n",
    "#bt.plotTrades()\n",
    "#plt.subplot(3,1,2)\n",
    "#bt.pnl.plot(style='x-')\n",
    "#plt.subplot(3,1,3)\n",
    "plt.plot(learning_progress)\n",
    "\n",
    "plt.savefig('plt/summary'+'.png', bbox_inches='tight', pad_inches=1, dpi=72)\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
